üß† Stack Overflow Data Insights ‚Äî Answer Gaps Analysisüìñ IntroductionThis project was developed as part of a technical data assessment, simulating real-world data delivery conditions. It covers the full analytical lifecycle‚Äîfrom sourcing and modeling data, to building an analytical data model and generating visualizations that surface actionable insights.The exercise focuses on the Stack Overflow public dataset, with the primary goal of identifying which topics (tags) demonstrate the highest need for answers (i.e., the greatest gap between demand and resolution).The project demonstrates production-minded data practices, including:End-to-end data sourcing, transformation, and presentation.Dimensional data modeling (Star Schema) in Google BigQuery.Utilizing dbt (Data Build Tool) for modular data transformation and testing.Looker Studio for clear data storytelling and insights visualization.üéØ Objective: Which topics have the highest need for answers?To address this core business question, the project analyzes questions, answers, users, and tags from the Stack Overflow public dataset. The data is modeled into an analytical schema optimized for reporting and exploration.The Need for Answers (Demand Index) is defined as a synthetic metric combining demand (views) with the lack of resolution (unanswered status).üß© Project Architecture: Dimensional Star SchemaThe data pipeline utilizes a robust dimensional approach, with a central fact table surrounded by key dimension tables.Fact TablesTableDescriptionPrimary Key (PK)fact_questionsThe central fact table. Captures each question‚Äôs core metrics (views, score, answer_count, is_answered, etc.).question_idfact_question_tagA bridge table connecting questions to their tags (many-to-many relationship).question_tag_idDimension TablesTableDescriptionExample Fieldsdim_usersInformation about the question authors (owners) and their reputation metrics.user_id, display_name, reputationdim_tagsMetadata for each tag, its name, and usage frequency.tag_id, tag_name, countdim_timeA standard calendar dimension for analyzing question creation and activity dates.time_id, full_date, year, monthüõ†Ô∏è Data Transformation (dbt) and QualityThe transformation logic and the creation of the analytical schema were entirely implemented using dbt.Naming Conventions and TestingAreaProduction PracticeDescriptionModelingLayered ArchitectureModels are separated into staging, intermediate, and marts (dim_ and fct_) layers for modularity.TestingGeneric Testingunique and not_null tests are enforced on all Primary Keys (PK) and Foreign Keys (FK) to guarantee data integrity.SourcesSource DeclarationAll raw tables are defined using the dbt source() block for clear data lineage management.DocumentationComprehensive DocumentationEvery model, column, and source is documented in .yml files, facilitating automatic documentation generation (dbt docs).Key Demand MetricsThe following metrics were computed to identify the "underserved" topics:Unresolved Questions: COUNT of questions where is_answered = 0 (no answer received).Total Views of Unresolved: SUM of the view counts for all unanswered questions.Demand Index (Final Metric): (Total Views of Unresolved / Unresolved Questions). This metric quantifies the average number of views per unresolved problem, serving as the ultimate indicator of high user frustration/demand.üìà Insights Visualization (Looker Studio)The analysis culminates in a Looker Studio dashboard designed to quickly convey the answer gaps.Primary Visualization: A Scatter Chart comparing the Count of Unresolved Questions (X-Axis) against the Demand Index (Y-Axis).Insight: Tags located in the upper-right quadrant represent the greatest overlap of persistent problems and high user demand.Report Access: [Insert Link to your public Looker Studio report]üöÄ Getting StartedPrerequisitesAccess to Google BigQuery and permissions to create datasets.dbt-bigquery installed locally (via pip).Local SetupClone the repository: git clone [URL]Configure your profiles.yml file (local to your machine) with your BigQuery project credentials.Running the TransformationInstall dbt packages (if applicable): dbt depsRun data quality tests: dbt testBuild the entire data model: dbt buildThe fully transformed analytical tables will be created in your target BigQuery dataset, ready for consumption by Looker Studio.
